# SUS-hackatlon

# SUS â€” Smashing Unfair Schemes (Fraud Detection)

![Python](https://img.shields.io/badge/python-3.10%2B-blue) ![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

> **TL;DR** â€” Highâ€‘precision fraud detection powered by PCAâ€‘guided feature selection, synthetic data augmentation and XGBoost. Reproducible, modular, and battleâ€‘tested â€“ *hire us already*.

---

## ğŸš€ Why You Should Care

- **Razorâ€‘sharp EDA** â€“ zero missing, one selfâ€‘loop, everything else spotless.  
- **Variance on a diet** â€“ PCA shows 4 features carry **75â€¯%** of the story â€“ we focus there.  
- **Classâ€‘imbalance annihilation** â€“ *2050* logâ€‘normal synthetic transactions to beef up the minority class.  
- **XGBoost supremacy** â€“ 1â€¯000â€‘combo grid search + early stopping (20) â†’ F1â€‘score that sings.  
- **Reproducibility first** â€“ same results, every machine, every time (Conda + seed).

---

## ğŸ—‚ Repo Layout

````text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # original .csv (ğŸ”’ never committed)
â”‚   â””â”€â”€ processed/      # cleaned & augmented
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_pca.ipynb
â”‚   â”œâ”€â”€ 03_synthetic_generation.ipynb
â”‚   â””â”€â”€ 04_modelling.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/           # loading & preprocessing
â”‚   â”œâ”€â”€ features/       # feature engineering
â”‚   â”œâ”€â”€ models/         # training & inference
â”‚   â””â”€â”€ visualization/  # plots
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ sus_fraud_report.pdf
â”œâ”€â”€ environment.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
````

---

## âš¡ï¸ Quickstart

```bash
# 1. Clone me (you know you want to)
git clone https://github.com/YOUR-USERNAME/sus-fraud-detection.git
cd sus-fraud-detection

# 2. Set up environment
conda env create -f environment.yml
conda activate sus

# 3. Run the full pipeline
make run          # executes: clean, augment, train, evaluate

# Or notebook your way through:
jupyter lab
```

---

## ğŸ”§ Pipeline in 60Â sec

1. **`clean_data.py`** â€” Removes anomalies, converts types, and laughs at nulls.
2. **`augment.py`** â€” Fits logâ€‘normal distributions to key fraud features and spits out 2â€¯050 new bad boys.
3. **`train.py`** â€” Runs grid search over `eta`, `subsample`, `gamma` (1â€¯000 combos), with early stopping. Saves the best model to `models/xgb_best.json`.
4. **`evaluate.py`** â€” Prints and plots confusion matrix, ROC, PR curve, and dumps a `metrics.json`.

All scripts are driven by **Hydra** configs in `config/` â€“ tweak without touching code.

---

## ğŸ“Š Result Highlights (test set)

| Metric     | Legit | Fraud |
|-----------:|------:|------:|
| Precision  | 0.92  | 0.84  |
| Recall     | 0.96  | 0.88  |
| F1â€‘score   | 0.94  | 0.86  |

<sub>*Numbers are illustrative; check the current `reports/metrics.json` for fresh results.*</sub>

---

## ğŸ¤ Contributing

Pull requests welcome **if they make things faster, cleaner, or more sarcastic**. Open an issue first for major changes. Remember to run `pre-commit`.

---

## ğŸ“„ License

MIT â€” because lifeâ€™s too short for restrictive licenses. See `LICENSE` for details.

---

## ğŸ“ Citation

If this repo saves your thesis/job, cite the accompanying report:

```bibtex
@techreport{mazzotta2025sus,
  title        = {SUS â€” Smashing Unfair Schemes: Fraud Detection with Synthetic Augmentation and XGBoost},
  author       = {De Martino, Francesco and Mazzotta, Roberto Magno and Mazzocchi, Beatrice},
  year         = {2025},
  institution  = {Sapienza University of Rome}
}
```

---

### ğŸ™‹â€â™‚ï¸ Author â€” **Giuggini** (a.k.a. *BruttiÂ Manzoni*)

I turn messy data into clean wins. **Hire me, letâ€™s kill fraud together.**
